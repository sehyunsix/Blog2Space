import { AutoModel, AutoTokenizer } from '@huggingface/transformers'

// Worker version: 2.0 - 4-stage progress display
const DEFAULT_MODEL_ID = 'Xenova/all-MiniLM-L6-v2'
let model = null
let tokenizer = null
let device = null
let lastProgressUpdate = 0
const PROGRESS_THROTTLE_MS = 200 // UI ì—…ë°ì´íŠ¸ëŠ” 200msë§ˆë‹¤ë§Œ

self.onmessage = async (event) => {
  const { type, payload } = event.data

  if (type === 'load-model') {
    try {
      const modelId = payload?.modelId || DEFAULT_MODEL_ID

      // ì¦‰ì‹œ ì²« ë²ˆì§¸ progress ë©”ì‹œì§€ ë³´ë‚´ê¸°
      self.postMessage({
        type: 'progress',
        payload: {
          percentage: 0,
          status: `[1/4] ì´ˆê¸°í™” ì¤‘...`,
        },
      })

      // WebGPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
      let isWebGPUAvailable = false
      if (navigator.gpu) {
        try {
          isWebGPUAvailable = !!(await navigator.gpu.requestAdapter())
        } catch (e) {
          console.log('WebGPU not available:', e)
        }
      }

      device = isWebGPUAvailable ? 'webgpu' : 'wasm'

      self.postMessage({
        type: 'progress',
        payload: {
          percentage: 5,
          status: `[1/4] í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì¤‘...`,
        },
      })

      tokenizer = await AutoTokenizer.from_pretrained(modelId, {
        progress_callback: (progress) => {
          if (progress.status === 'progress') {
            const percentage = 5 + Math.round((progress.loaded / progress.total) * 15)
            self.postMessage({
              type: 'progress',
              payload: {
                percentage,
                status: `[1/4] í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì¤‘...`,
              },
            })
          }
        },
      })

      self.postMessage({
        type: 'progress',
        payload: {
          percentage: 20,
          status: `[2/4] ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘...`,
        },
      })

      model = await AutoModel.from_pretrained(modelId, {
        device,
        dtype: device === 'webgpu' ? 'fp32' : 'q8',
        progress_callback: (progress) => {
          if (progress.status === 'progress') {
            const percentage = 20 + Math.round((progress.loaded / progress.total) * 60)
            const loadedMB = (progress.loaded / 1024 / 1024).toFixed(1)
            const totalMB = (progress.total / 1024 / 1024).toFixed(1)

            // UI ì—…ë°ì´íŠ¸ (throttle ì ìš©)
            const now = Date.now()
            const isLastChunk = progress.loaded === progress.total

            if (now - lastProgressUpdate > PROGRESS_THROTTLE_MS || isLastChunk) {
              lastProgressUpdate = now
              self.postMessage({
                type: 'progress',
                payload: {
                  percentage,
                  status: `[2/4] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... ${loadedMB}MB / ${totalMB}MB`,
                },
              })
            }
          } else if (progress.status === 'download') {
            self.postMessage({
              type: 'progress',
              payload: {
                percentage: 25,
                status: `[2/4] íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘...`,
              },
            })
          } else if (progress.status === 'done') {
            // ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ ì´ˆê¸°í™” ì‹œì‘ ì•ˆë‚´
            self.postMessage({
              type: 'progress',
              payload: {
                percentage: 85,
                status: '[3/4] ëª¨ë¸ ì´ˆê¸°í™” ì¤‘... (ONNX Runtime)',
              },
            })
          } else if (progress.status === 'ready') {
            self.postMessage({
              type: 'progress',
              payload: {
                percentage: 95,
                status: '[4/4] ìµœì¢… ì„¤ì • ì¤‘...',
              },
            })
          }
        },
      })

      // ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€
      self.postMessage({
        type: 'progress',
        payload: {
          percentage: 100,
          status: 'âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!',
        },
      })

      self.postMessage({
        type: 'ready',
        payload: { device, modelId },
      })
    } catch (error) {
      console.error('Model loading error:', error)
      self.postMessage({
        type: 'error',
        payload: error instanceof Error ? error.message : String(error),
      })
    }
  } else if (type === 'embed' && model && tokenizer) {
    try {
      const { texts } = payload

      // 1ë‹¨ê³„: í† í¬ë‚˜ì´ì§• (í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜)
      self.postMessage({
        type: 'progress',
        payload: {
          percentage: 40,
          status: `[1/3] í† í¬ë‚˜ì´ì§• ì¤‘... (${texts.length}ê°œ í…ìŠ¤íŠ¸)`,
        },
      })

      const inputs = tokenizer(texts, {
        padding: true,
        truncation: true,
      })

      // 2ë‹¨ê³„: ëª¨ë¸ ì‹¤í–‰ (ì„ë² ë”© ë²¡í„° ìƒì„±)
      self.postMessage({
        type: 'progress',
        payload: {
          percentage: 50,
          status: `[2/3] AI ëª¨ë¸ ì‹¤í–‰ ì¤‘... (${texts.length}ê°œ ì²˜ë¦¬)`,
        },
      })

      const outputs = await model(inputs)

      // 3ë‹¨ê³„: Mean Pooling & ì •ê·œí™”
      self.postMessage({
        type: 'progress',
        payload: {
          percentage: 70,
          status: '[3/3] ì„ë² ë”© ë³€í™˜ ì¤‘... (í‰ê· í™”)',
        },
      })

      // Mean pooling
      const embeddings = []
      const hiddenStates = outputs.last_hidden_state
      const attentionMask = inputs.attention_mask

      for (let i = 0; i < texts.length; i++) {
        try {
          const embedding = meanPooling(hiddenStates, attentionMask, i)

          // NaN ì²´í¬ ë° ì •ê·œí™”
          const embeddingArray = Array.from(embedding)

          // NaNì´ë‚˜ Infinity ì²´í¬
          const hasInvalidValues = embeddingArray.some((v) => !isFinite(v))
          if (hasInvalidValues) {
            console.warn(`âš ï¸ Invalid embedding at index ${i}, using fallback`)
            console.warn(`âš ï¸ ë¬¸ì œ í…ìŠ¤íŠ¸ (${i}):`, texts[i]?.substring(0, 100))
            // fallback: ì‘ì€ ëœë¤ ë²¡í„°
            const fallbackEmbedding = new Array(embeddingArray.length)
              .fill(0)
              .map(() => (Math.random() - 0.5) * 0.01)
            embeddings.push(fallbackEmbedding)
            continue
          }

          // L2 ì •ê·œí™” (ë²¡í„° ê¸¸ì´ë¥¼ 1ë¡œ ë§Œë“¤ê¸°)
          const norm = Math.sqrt(embeddingArray.reduce((sum, val) => sum + val * val, 0))
          const normalizedEmbedding =
            norm > 1e-10
              ? embeddingArray.map((v) => v / norm)
              : new Array(embeddingArray.length).fill(0).map(() => (Math.random() - 0.5) * 0.01) // normì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ëœë¤ ë²¡í„°

          // ì •ê·œí™” í›„ì—ë„ NaN ì²´í¬
          if (normalizedEmbedding.some((v) => !isFinite(v))) {
            console.warn(`âš ï¸ Normalization failed at index ${i}, using fallback`)
            const fallbackEmbedding = new Array(normalizedEmbedding.length)
              .fill(0)
              .map(() => (Math.random() - 0.5) * 0.01)
            embeddings.push(fallbackEmbedding)
            continue
          }

          embeddings.push(normalizedEmbedding)
        } catch (error) {
          console.error(`âŒ Error processing text ${i}:`, error)
          // fallback: ì‘ì€ ëœë¤ ë²¡í„°
          const hiddenSize = hiddenStates.dims[2]
          const fallbackEmbedding = new Array(hiddenSize)
            .fill(0)
            .map(() => (Math.random() - 0.5) * 0.01)
          embeddings.push(fallbackEmbedding)
        }

        // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        if (i % 10 === 0 || i === texts.length - 1) {
          const progress = 70 + Math.round(((i + 1) / texts.length) * 30)
          self.postMessage({
            type: 'progress',
            payload: {
              percentage: progress,
              status: `[3/3] ì„ë² ë”© ë³€í™˜ ì¤‘... ${i + 1}/${texts.length}`,
            },
          })
        }
      }

      // ìµœì¢… ê²€ì¦
      if (embeddings.length !== texts.length) {
        throw new Error(`ì„ë² ë”© ê°œìˆ˜ ë¶ˆì¼ì¹˜: ${embeddings.length} vs ${texts.length}`)
      }

      // ëª¨ë“  ì„ë² ë”©ì´ ìœ íš¨í•œì§€ ìµœì¢… í™•ì¸
      const invalidCount = embeddings.filter((emb) => emb.some((v) => !isFinite(v))).length
      if (invalidCount > 0) {
        console.error(`âŒ ${invalidCount}ê°œì˜ ì„ë² ë”©ì— ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì´ ìˆìŠµë‹ˆë‹¤`)
        throw new Error(`${invalidCount}ê°œì˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨`)
      }

      console.log(`âœ… Embeddings generated: ${embeddings.length}`)
      console.log(`ğŸ“Š First embedding sample (10 values):`, embeddings[0]?.slice(0, 10))
      console.log(`ğŸ“Š Embedding stats:`, {
        min: Math.min(...embeddings[0]),
        max: Math.max(...embeddings[0]),
        avg: embeddings[0].reduce((a, b) => a + b, 0) / embeddings[0].length,
      })

      self.postMessage({
        type: 'embeddings',
        payload: { embeddings },
      })
    } catch (error) {
      console.error('Embedding error:', error)
      self.postMessage({
        type: 'error',
        payload: error instanceof Error ? error.message : String(error),
      })
    }
  }
}

// Mean pooling í•¨ìˆ˜ (ë°°ì¹˜ ì²˜ë¦¬ìš©)
function meanPooling(hiddenStates, attentionMask, batchIndex) {
  const seqLength = hiddenStates.dims[1]
  const hiddenSize = hiddenStates.dims[2]
  const data = hiddenStates.data

  const result = new Float32Array(hiddenSize)
  let tokenCount = 0

  const batchOffset = batchIndex * seqLength * hiddenSize

  for (let i = 0; i < seqLength; i++) {
    const maskValue = attentionMask.data[batchIndex * seqLength + i]
    if (maskValue === 1 || maskValue === 1n) {
      for (let j = 0; j < hiddenSize; j++) {
        const value = data[batchOffset + i * hiddenSize + j]
        // NaN/Infinity ì²´í¬
        if (isFinite(value)) {
          result[j] += value
        }
      }
      tokenCount++
    }
  }

  // í‰ê·  ê³„ì‚°
  if (tokenCount > 0) {
    for (let j = 0; j < hiddenSize; j++) {
      result[j] /= tokenCount
    }
  } else {
    // tokenCountê°€ 0ì´ë©´ ê²½ê³ í•˜ê³  ì‘ì€ ëœë¤ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    console.warn(`âš ï¸ ë°°ì¹˜ ${batchIndex}: ìœ íš¨í•œ í† í°ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„ë² ë”© ì‚¬ìš©`)
    for (let j = 0; j < hiddenSize; j++) {
      result[j] = (Math.random() - 0.5) * 0.01 // ì‘ì€ ëœë¤ ê°’
    }
  }

  return result
}
